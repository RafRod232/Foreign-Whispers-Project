1
00:00:04,800 --> 00:00:10,160
when yuval noah harari published his first  book sapiens in 2014 about the history of the  

2
00:00:10,160 --> 00:00:16,160
human species it became a global bestseller in  turn the little-known israeli history professor  

3
00:00:16,160 --> 00:00:19,120
into one of the most popular  writers and thinkers on the planet  

4
00:00:19,760 --> 00:00:24,320
but when we met with harari in tel aviv this  summer it wasn't our species past that concerned  

5
00:00:24,320 --> 00:00:30,480
him it was our future harare believes we may be  on the brink of creating not just a new enhanced  

6
00:00:30,480 --> 00:00:36,560
species of human but an entirely new kind of  being one that's far more intelligent than we are  

7
00:00:37,200 --> 00:00:40,960
it sounds like science fiction but  you've all know a harare says it's  

8
00:00:40,960 --> 00:00:46,880
actually much more dangerous than that  the story will continue in a moment

9
00:00:50,400 --> 00:00:54,560
you said we are one of the last generations of  homo sapiens within a century or two earth will be  

10
00:00:54,560 --> 00:01:00,080
dominated by entities that are more different from  us than we are different from chimpanzees yeah  

11
00:01:00,880 --> 00:01:05,280
what the hell does that mean that freaked  me out you know we'll soon have the power  

12
00:01:05,840 --> 00:01:13,920
to re-engineer our bodies and brains whether it is  with genetic engineering or by directly connecting  

13
00:01:13,920 --> 00:01:20,400
brains to computers or by creating  completely non-organic entities  

14
00:01:20,960 --> 00:01:26,400
artificial intelligence which is not based at  all on the organic body and the organic brain  

15
00:01:27,200 --> 00:01:32,880
and these technologies are developing at  breakneck speed if that is true then it  

16
00:01:32,880 --> 00:01:41,440
creates a whole other species this is something  which is way beyond just another species you all  

17
00:01:41,440 --> 00:01:46,240
know a harare is talking about the race to  develop artificial intelligence as well as  

18
00:01:46,240 --> 00:01:51,520
other technologies like gene editing that could  one day enable parents to create smarter or more  

19
00:01:51,520 --> 00:01:57,360
attractive children and brain computer interfaces  that could result in human machine hybrids  

20
00:01:58,160 --> 00:02:04,480
what does that do to a society i mean it  seems like the rich will have access whereas  

21
00:02:04,480 --> 00:02:10,160
others wouldn't one of the dangers is that we  will see in the coming decades a process of  

22
00:02:11,520 --> 00:02:17,360
greater inequality than in any previous time  in history because for the first time it will  

23
00:02:17,360 --> 00:02:24,240
be real biological inequality if the new  technologies are available only to the rich  

24
00:02:24,240 --> 00:02:31,760
or only to people from a certain country  then homo sapiens will split into different  

25
00:02:31,760 --> 00:02:37,360
biological costs because they really have  different bodies and different abilities  

26
00:02:38,720 --> 00:02:44,400
ferrari has spent the last few years lecturing  and writing about what may lie ahead for humankind  

27
00:02:45,440 --> 00:02:53,360
in the coming generations we will learn how  to engineer bodies and brains and minds he's  

28
00:02:53,360 --> 00:02:59,360
written two books about the challenges we face in  the future homo deus and 21 lessons for the 21st  

29
00:02:59,360 --> 00:03:05,280
century which along with sapiens have sold more  than 35 million copies and been translated into  

30
00:03:05,280 --> 00:03:11,280
65 languages his writings have been recommended  by president barack obama as well as tech moguls  

31
00:03:11,280 --> 00:03:18,080
bill gates and mark zuckerberg you raise warnings  about technology you're also embraced by a lot of  

32
00:03:18,080 --> 00:03:23,680
folks in silicon valley yeah isn't that sort of  a contradiction they are a bit afraid of their  

33
00:03:23,680 --> 00:03:32,000
own power that they have realized the immense  influence they have over the world over the  

34
00:03:32,000 --> 00:03:37,440
course of evolution really and i think that spooks  at least some of them and that's a good thing  

35
00:03:38,640 --> 00:03:47,280
um and this is why they are kind of to some  extent open to listening you started as a  

36
00:03:47,280 --> 00:03:53,360
history professor what do you call yourself now  i'm still a historian but i think history is the  

37
00:03:53,360 --> 00:04:00,640
study of change not just the study of the past  but it covers the future as well harari got his  

38
00:04:00,640 --> 00:04:07,040
phd in history at oxford and lives in israel  where the past is still very present he took  

39
00:04:07,040 --> 00:04:13,600
us to this archaeological site called tel gezer  four five thousand years ago this was one of the  

40
00:04:13,600 --> 00:04:19,680
biggest cities in the area harare says cities  like this were only possible because about 70  

41
00:04:19,680 --> 00:04:26,720
000 years ago our species homo sapiens experienced  a cognitive change that helped us create language  

42
00:04:26,720 --> 00:04:32,400
which then made it possible for us to cooperate in  large groups and drive neanderthals and all other  

43
00:04:32,400 --> 00:04:39,040
less cooperative human species into extinction  harare fears we are now the ones at risk of  

44
00:04:39,040 --> 00:04:45,520
being dominated by artificial intelligence maybe  the biggest thing that we are facing is really  

45
00:04:45,520 --> 00:04:52,960
a kind of evolutionary divergence for millions of  years intelligence and consciousness went together  

46
00:04:53,520 --> 00:04:58,240
consciousness is the ability to feel things  like pain and pleasure and love and hate  

47
00:04:58,800 --> 00:05:05,680
intelligence is the ability to solve problems  but computers or artificial intelligence  

48
00:05:05,680 --> 00:05:10,960
they don't have consciousness they just have  intelligence they solve problems in a completely  

49
00:05:10,960 --> 00:05:16,640
different way than us now in science fiction  it's often assumed that as computers will become  

50
00:05:16,640 --> 00:05:23,040
more and more intelligent they will inevitably  also gain consciousness but actually it's much  

51
00:05:23,040 --> 00:05:28,240
more frightening than that in a way they will be  able to solve more and more problems better than  

52
00:05:28,240 --> 00:05:34,720
us without having any consciousness any feelings  and they will have power over us they are already  

53
00:05:34,720 --> 00:05:40,640
gaining power over us some lenders routinely use  complex artificial intelligence algorithms to  

54
00:05:40,640 --> 00:05:47,200
determine who qualifies for loans global financial  markets are moved by decisions made by machines  

55
00:05:47,200 --> 00:05:51,840
analyzing huge amounts of data in ways even  their programmers don't always understand  

56
00:05:52,960 --> 00:05:58,320
harare says the countries and companies that  control the most data will in the future be the  

57
00:05:58,320 --> 00:06:04,160
ones that control the world today in the world  data is worth much more than money 10 years ago  

58
00:06:04,160 --> 00:06:10,480
you had these big corporations paying billions  and billions for whatsapp for instagram and people  

59
00:06:10,480 --> 00:06:17,280
wondered are they crazy why do they pay billions  to get this application that doesn't produce any  

60
00:06:17,280 --> 00:06:24,160
money and the reason why because it produced data  and data is the key the world is increasingly kind  

61
00:06:24,160 --> 00:06:32,160
of cut up into spheres of of of data collection  of data harvesting uh in the cold war you had the  

62
00:06:32,160 --> 00:06:38,080
iron curtain now we have the silicon curtain  between the usa and china and where does the  

63
00:06:38,080 --> 00:06:45,440
data go california or does it go to shenzhen and  to shanghai into beijing harare is concerned the  

64
00:06:45,440 --> 00:06:51,040
pandemic has opened the door for more intrusive  kinds of data collection including biometric data  

65
00:06:51,680 --> 00:06:57,920
what is biometric data it's data about what's  happening inside my body what we've seen so far  

66
00:06:57,920 --> 00:07:04,480
it's corporations and governments collecting data  about where we go who we meet what movies we watch  

67
00:07:05,200 --> 00:07:13,440
the next phase is the surveillance going under  our skin i'm wearing a like a tracker that tracks  

68
00:07:13,440 --> 00:07:19,200
my heart rate my sleep i don't know where that  information is going where are the kgb agent on  

69
00:07:19,200 --> 00:07:25,040
your wrist willingly and i think it's benefiting  me and it is benefiting i mean the whole thing is  

70
00:07:25,040 --> 00:07:32,320
that it's not just dystopian it's also utopian  i mean this kind of data can also enable us to  

71
00:07:32,320 --> 00:07:40,160
create the best healthcare system in history the  question is what else is being done with that data  

72
00:07:40,160 --> 00:07:46,640
and who supervises it who regulates it earlier  this year the israeli government gave its citizens  

73
00:07:46,640 --> 00:07:52,960
health data to pfizer to get priority access to  their vaccine the data did not include individual  

74
00:07:52,960 --> 00:08:01,120
citizens identities so what does pfizer want the  data of all israelis for because to develop new  

75
00:08:01,120 --> 00:08:08,560
medicines new treatments you need the medical data  increasingly that's the basis for how for medical  

76
00:08:08,560 --> 00:08:13,680
research and of course it's not all bad harare  has been criticized for pointing out problems  

77
00:08:13,680 --> 00:08:18,880
without offering solutions but he does have  some ideas about how to limit the misuse of data  

78
00:08:19,680 --> 00:08:27,040
one key rule is that if you get my  data the data should be used to help me  

79
00:08:27,040 --> 00:08:36,160
and not to manipulate me another key rule that  whenever you increase surveillance of individuals  

80
00:08:36,160 --> 00:08:42,400
you should simultaneously increase surveillance  of the corporation and governments and the people  

81
00:08:42,400 --> 00:08:48,320
at the top and the third principle is that never  allow all the data to be concentrated in one place  

82
00:08:48,960 --> 00:08:56,400
that's the recipe for a dictatorship netflix tells  us what to watch and amazon tells us what to buy  

83
00:08:57,360 --> 00:09:04,240
eventually within 10 or 20 or 30 years such  algorithms could also tell you what to study  

84
00:09:04,240 --> 00:09:12,240
at college and where to work and whom to marry and  even whom to vote for without greater regulation  

85
00:09:12,240 --> 00:09:17,120
harare believes we're at risk of becoming  what he calls hacked humans what does that  

86
00:09:17,120 --> 00:09:22,720
mean to hack a human being is to get to know  that person better than they know themselves  

87
00:09:23,600 --> 00:09:29,680
and based on that to increasingly manipulate  you this outside system it has the potential  

88
00:09:29,680 --> 00:09:38,000
to remember everything everything you ever did  and uh to analyze and find patterns in this data  

89
00:09:38,000 --> 00:09:45,520
and to get a much better idea of who you  really are i came out as gay when i was 21  

90
00:09:45,520 --> 00:09:50,640
it should have been obvious to me when i was 15  that i'm gay but something in the mind blocked it  

91
00:09:51,520 --> 00:09:57,520
now if you think about a teenager today facebook  can know that they are gay or amazon can know that  

92
00:09:57,520 --> 00:10:05,680
they are gay long before they do just based on  analyzing patterns and based on that you can tell  

93
00:10:06,560 --> 00:10:12,240
somebody's sexual orientation completely and what  does it mean if you live in iran or if you live  

94
00:10:12,240 --> 00:10:17,440
in russia or in some other homophobic country  and the police know that you're gay even before  

95
00:10:17,440 --> 00:10:24,000
you know it when people think about data they  think about companies finding out what their  

96
00:10:25,360 --> 00:10:31,120
likes and dislikes are but the data that you're  talking about it goes much deeper than that like  

97
00:10:31,120 --> 00:10:39,040
think in 20 years when the entire personal history  of every journalist every judge every politician  

98
00:10:39,040 --> 00:10:46,000
every military officer is held by somebody  in beijing or in washington your ability to  

99
00:10:46,000 --> 00:10:52,800
manipulate them is like nothing before in history  it's really good ferrari lives outside tel aviv  

100
00:10:52,800 --> 00:10:59,440
with his husband itsekyahav they've been together  for nearly 20 years it was yahov who read harare's  

101
00:10:59,440 --> 00:11:04,560
lecture notes for a history course and convinced  him to turn them into his first book sapiens  

102
00:11:05,200 --> 00:11:11,520
i read the lessons i couldn't stop talking  about it for me it was clear that it could be  

103
00:11:11,520 --> 00:11:17,440
a huge bestseller yahov is now hirari's agent  and together they started a company called  

104
00:11:17,440 --> 00:11:22,720
sapienship they're creating an interactive exhibit  that'll take visitors through the history of human  

105
00:11:22,720 --> 00:11:29,600
evolution and challenge them to think about the  future of mankind harare also just published the  

106
00:11:29,600 --> 00:11:35,040
second installment of a graphic novel based on  sapience and he's teaching courses at israel's  

107
00:11:35,040 --> 00:11:40,480
hebrew university in ethics and philosophy  for computer scientists and bioengineers  

108
00:11:41,120 --> 00:11:48,240
when people write code they are reshaping  politics and economics and ethics and the  

109
00:11:48,240 --> 00:11:54,880
structure of human society when i think of coders  and engineers i don't think of philosophers and  

110
00:11:54,880 --> 00:12:00,160
poets it's not the case now but it should  be the case because they are increasingly  

111
00:12:00,160 --> 00:12:06,080
solving philosophical and poetical riddles if  you're designing you know a self-driving car  

112
00:12:06,960 --> 00:12:10,880
so the self-driving car will  need to make ethical decisions  

113
00:12:11,600 --> 00:12:17,200
like suddenly a kid jumps in front of the car and  the only way to to to prevent running over the kid  

114
00:12:17,200 --> 00:12:23,440
is to swerve to the side and be hit by a truck  and your own owner who is asleep in the back seat  

115
00:12:23,440 --> 00:12:28,720
will might be killed you need to tell the  algorithm what to do in this situation  

116
00:12:29,600 --> 00:12:33,040
so you need to actually solve the  philosophical question who to kill  

117
00:12:34,320 --> 00:12:39,360
last month the united nations suggested a  moratorium on artificial intelligence systems that  

118
00:12:39,360 --> 00:12:45,120
seriously threaten human rights until safeguards  are agreed upon and advisers to president biden  

119
00:12:45,120 --> 00:12:51,040
are proposing what they call a bill of rights to  guard against some of the new technologies harori  

120
00:12:51,040 --> 00:12:55,920
says just as homo sapiens learned to cooperate  with each other many thousands of years ago  

121
00:12:55,920 --> 00:13:01,680
we need to cooperate now certainly now we are  at the point when we need global cooperation  

122
00:13:02,320 --> 00:13:08,240
you cannot regulate the explosive power of  artificial intelligence on a national level  

123
00:13:08,800 --> 00:13:15,360
i'm not trying to kind of prophesy what will  happen i'm trying to warn people about the most  

124
00:13:15,360 --> 00:13:26,720
dangerous possibilities in the hope that we  will do something in the present to prevent them